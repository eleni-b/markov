{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Παραδοτέο 1\n",
    "\n",
    "Παρακάτω φαίνεται η υλοποίηση της Markov Chain όπου υπολογίζουμε τη μέση τιμή των εκτιμήσεων και τη διασπορά τους. \n",
    "\n",
    "\n",
    "Η θεωρητικά αναμενόμενη εκτίμηση υπολογίζεται ως εξής: Η πιθανότητα $P [ X_n = 0 | X_0 = 0] $ προκύπτει από το ${p_{00}}^{(n)}$, δηλαδή το πρώτο στοιχείο του πίνακα. Από το χαρακτηριστικό πολυώνυμο $\\lambda I - P$, προκύπτει η χαρακτηρηστική εξίσωση $\\frac{(\\lambda - 1)}{3} (3 {\\lambda}^2+ \\lambda + p)$, όπου $p = 1/6$. Συνεπώς, η διακρίνουσα είναι $\\Delta = -1$, και οι ιδιοτιμές είναι ${\\lambda}_1 = 1, {\\lambda}_{2,3} = \\frac{-1 \\pm i}{6} $ και λύνοντας το σύστημα για τα ιδιοδιανύσματα, βρίσκουμε ότι τελικά ισχύει ότι: \n",
    "        ${p_{00}}^{(n)} = \\frac{1}{25} + \\frac{24}{25 {(3 \\sqrt(2))}^n}\\cos(\\frac{3 \\pi n}{4}) + \\frac{18}{25 {(3 \\sqrt(2))}^n}\\sin(\\frac{3 \\pi n}{4})$\n",
    "\n",
    "Έτσι, αντικαθιστώντας όπου $n = 40$, δηλαδή τον αριθμό των steps, βρίσκουμε ότι η θεωρητική εκτίμηση ισούται με $0.4$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    On iteration 0, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 801 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04005 \n",
      "    \n",
      "\n",
      "    On iteration 1, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 793 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03965 \n",
      "    \n",
      "\n",
      "    On iteration 2, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 758 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0379 \n",
      "    \n",
      "\n",
      "    On iteration 3, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 800 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04 \n",
      "    \n",
      "\n",
      "    On iteration 4, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 740 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.037 \n",
      "    \n",
      "\n",
      "    On iteration 5, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 804 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0402 \n",
      "    \n",
      "\n",
      "    On iteration 6, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 831 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04155 \n",
      "    \n",
      "\n",
      "    On iteration 7, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 833 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04165 \n",
      "    \n",
      "\n",
      "    On iteration 8, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 792 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0396 \n",
      "    \n",
      "\n",
      "    On iteration 9, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 831 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04155 \n",
      "    \n",
      "\n",
      "    On iteration 10, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 788 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0394 \n",
      "    \n",
      "\n",
      "    On iteration 11, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 772 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0386 \n",
      "    \n",
      "\n",
      "    On iteration 12, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 784 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0392 \n",
      "    \n",
      "\n",
      "    On iteration 13, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 823 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04115 \n",
      "    \n",
      "\n",
      "    On iteration 14, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 813 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04065 \n",
      "    \n",
      "\n",
      "    On iteration 15, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 780 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.039 \n",
      "    \n",
      "\n",
      "    On iteration 16, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 805 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04025 \n",
      "    \n",
      "\n",
      "    On iteration 17, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 772 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0386 \n",
      "    \n",
      "\n",
      "    On iteration 18, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 806 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0403 \n",
      "    \n",
      "\n",
      "    On iteration 19, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 785 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03925 \n",
      "    \n",
      "\n",
      "    On iteration 20, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 769 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03845 \n",
      "    \n",
      "\n",
      "    On iteration 21, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 762 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0381 \n",
      "    \n",
      "\n",
      "    On iteration 22, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 776 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0388 \n",
      "    \n",
      "\n",
      "    On iteration 23, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 855 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04275 \n",
      "    \n",
      "\n",
      "    On iteration 24, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 801 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04005 \n",
      "    \n",
      "\n",
      "    On iteration 25, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 785 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03925 \n",
      "    \n",
      "\n",
      "    On iteration 26, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 799 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03995 \n",
      "    \n",
      "\n",
      "    On iteration 27, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 838 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0419 \n",
      "    \n",
      "\n",
      "    On iteration 28, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 773 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03865 \n",
      "    \n",
      "\n",
      "    On iteration 29, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 804 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0402 \n",
      "    \n",
      "\n",
      "    On iteration 30, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 758 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0379 \n",
      "    \n",
      "\n",
      "    On iteration 31, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 842 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0421 \n",
      "    \n",
      "\n",
      "    On iteration 32, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 787 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03935 \n",
      "    \n",
      "\n",
      "    On iteration 33, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 808 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0404 \n",
      "    \n",
      "\n",
      "    On iteration 34, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 788 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0394 \n",
      "    \n",
      "\n",
      "    On iteration 35, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 812 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0406 \n",
      "    \n",
      "\n",
      "    On iteration 36, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 798 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0399 \n",
      "    \n",
      "\n",
      "    On iteration 37, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 818 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0409 \n",
      "    \n",
      "\n",
      "    On iteration 38, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 780 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.039 \n",
      "    \n",
      "\n",
      "    On iteration 39, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 886 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0443 \n",
      "    \n",
      "\n",
      "    On iteration 40, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 789 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03945 \n",
      "    \n",
      "\n",
      "    On iteration 41, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 868 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0434 \n",
      "    \n",
      "\n",
      "    On iteration 42, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 766 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0383 \n",
      "    \n",
      "\n",
      "    On iteration 43, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 857 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04285 \n",
      "    \n",
      "\n",
      "    On iteration 44, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 771 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.03855 \n",
      "    \n",
      "\n",
      "    On iteration 45, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 808 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0404 \n",
      "    \n",
      "\n",
      "    On iteration 46, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 818 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0409 \n",
      "    \n",
      "\n",
      "    On iteration 47, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 842 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.0421 \n",
      "    \n",
      "\n",
      "    On iteration 48, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 823 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04115 \n",
      "    \n",
      "\n",
      "    On iteration 49, we executed 20000 times the first 40 steps of the markov chain\n",
      "    and we captured the running state in state zero 831 times.\n",
      "    So we estimate the Pr[X_40 = 0 | X_0 = 0] to be 0.04155 \n",
      "    \n",
      " \n",
      "    The sample mean is 0.04012 and the sample variance is 0.00000\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import statistics as stat\n",
    "from simple_markov_chain_lib import markov_chain\n",
    "\n",
    "random.seed(2016)  # for reproducibility\n",
    "\n",
    "p = 1/6\n",
    "\n",
    "init_probs = {0: 1.0} \n",
    " \n",
    "markov_table = {\n",
    "    0: {1: 1.},\n",
    "    1: {1: 2/3, 2: 1/3},\n",
    "    2: {0: p, 1: 1-p}\n",
    "}\n",
    " \n",
    "mc = markov_chain(markov_table, init_probs)\n",
    "\n",
    "N = 20000    # number of samples\n",
    "steps = 40   # the target time\n",
    "counter = 0  # to count the number of times the event {X_40  = 0} occurs\n",
    "M = 50       # number of iterations of initial experiment\n",
    "\n",
    "estimates=[]\n",
    "\n",
    "for k in range(M):\n",
    "    counter = 0\n",
    "    for i in range(N):\n",
    "        mc.start() \n",
    "        for j in range(steps):  mc.move()\n",
    "        if mc.running_state == 0:  counter += 1\n",
    "\n",
    "    phat = counter / N\n",
    "    \n",
    "    estimates.append(phat)\n",
    "\n",
    "    print(\"\"\"\n",
    "    On iteration {4}, we executed {0} times the first {1} steps of the markov chain\n",
    "    and we captured the running state in state zero {2} times.\n",
    "    So we estimate the Pr[X_{1} = 0 | X_0 = 0] to be {3} \n",
    "    \"\"\".format(N, steps, counter, phat, k))\n",
    "\n",
    "print(\n",
    "    \"\"\" \n",
    "    The sample mean is {0:.5f} and the sample variance is {1:.5f}\n",
    "    \"\"\".format(stat.mean(estimates), stat.variance(estimates))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Η μέση τιμή για Ν = 200, όπως φαίνεται αν τρέξουμε τον παραπάνω κώδικα είναι 0.03870, ενώ για Ν=20000 είναι 0.04012.\n",
    "2. Η θεωρητικά αναμενόμενη τιμή είναι 0.04, και παρατηρούμε ότι για μεγαλύτερο δείγμα Ν=20000 η μέση τιμή είναι πιο κοντά στην θεωρητική, οπότε έχουμε καλή προσέγγιση του αποτελέσματος.\n",
    "3. Η διασπορά για Ν=200 είναι 0.00020, ενώ για Ν=20000 είναι 0.\n",
    "4. Αλλάζουμε την γραμμή init_probs σε {2:1.0}, για να ξεκινάει από την κατάσταση 2. Και για τις δύο τιμές του Ν, οι τιμές για μέση τιμή και διασπορά είναι ακριβώς ίδιες για 50 επαναλήψεις, οπότε δεν επηρεάζεται τίποτα. \n",
    "\n",
    "\n",
    "## Παραδοτέο 2\n",
    "\n",
    "Για το παιχνίδι τέννις, φαίνεται στο κομμάτι κώδικα ο πίνακας πιθανοτήτων μετάβασης, καθώς και ο συμβολισμός των καταστάσεων. Προφανώς, η αρχική κατανομή είναι 1 στη θέση 0, καθώς το game ξεκινάει από το 0-0 (state 0). Χρησιμοποιήσαμε τον ίδιο σκελετό για τον κώδικά μας, μεταβάλλοντας το πλήθος των επαναλήψεων και παρατηρώντας την τιμή της εκτιμήτριας. \n",
    "Οι μεταβάσεις από τη μια κατάσταση της αλυσίδας στην άλλη είναι ως εξής: έστω ότι βρίσκεται στην κατάσταση 15-15 (state 4). Τότε με πιθανότητα p νικάει ο παίκτης Α, οπότε φτάνουμε στην κατάσταση 30-15 (state 7) με πιθανότητα p, ενώ με q  φτάνουμε στην κατάσταση 15-30 (state 8), και ούτω καθεξής. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    On iteration 0, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7294 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7294 \n",
      "    \n",
      "\n",
      "    On iteration 1, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7318 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7318 \n",
      "    \n",
      "\n",
      "    On iteration 2, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7298 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7298 \n",
      "    \n",
      "\n",
      "    On iteration 3, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7394 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7394 \n",
      "    \n",
      "\n",
      "    On iteration 4, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7397 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7397 \n",
      "    \n",
      "\n",
      "    On iteration 5, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7375 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7375 \n",
      "    \n",
      "\n",
      "    On iteration 6, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7359 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7359 \n",
      "    \n",
      "\n",
      "    On iteration 7, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7362 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7362 \n",
      "    \n",
      "\n",
      "    On iteration 8, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7314 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7314 \n",
      "    \n",
      "\n",
      "    On iteration 9, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7440 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.744 \n",
      "    \n",
      "\n",
      "    On iteration 10, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7359 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7359 \n",
      "    \n",
      "\n",
      "    On iteration 11, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7423 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7423 \n",
      "    \n",
      "\n",
      "    On iteration 12, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7328 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7328 \n",
      "    \n",
      "\n",
      "    On iteration 13, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7340 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.734 \n",
      "    \n",
      "\n",
      "    On iteration 14, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7366 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7366 \n",
      "    \n",
      "\n",
      "    On iteration 15, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7385 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7385 \n",
      "    \n",
      "\n",
      "    On iteration 16, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7287 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7287 \n",
      "    \n",
      "\n",
      "    On iteration 17, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7339 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7339 \n",
      "    \n",
      "\n",
      "    On iteration 18, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7405 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7405 \n",
      "    \n",
      "\n",
      "    On iteration 19, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7272 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7272 \n",
      "    \n",
      "\n",
      "    On iteration 20, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7398 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7398 \n",
      "    \n",
      "\n",
      "    On iteration 21, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7290 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.729 \n",
      "    \n",
      "\n",
      "    On iteration 22, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7371 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7371 \n",
      "    \n",
      "\n",
      "    On iteration 23, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7335 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7335 \n",
      "    \n",
      "\n",
      "    On iteration 24, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7393 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7393 \n",
      "    \n",
      "\n",
      "    On iteration 25, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7263 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7263 \n",
      "    \n",
      "\n",
      "    On iteration 26, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7413 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7413 \n",
      "    \n",
      "\n",
      "    On iteration 27, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7295 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7295 \n",
      "    \n",
      "\n",
      "    On iteration 28, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7355 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7355 \n",
      "    \n",
      "\n",
      "    On iteration 29, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7297 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7297 \n",
      "    \n",
      "\n",
      "    On iteration 30, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7424 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7424 \n",
      "    \n",
      "\n",
      "    On iteration 31, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7329 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7329 \n",
      "    \n",
      "\n",
      "    On iteration 32, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7385 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7385 \n",
      "    \n",
      "\n",
      "    On iteration 33, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7363 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7363 \n",
      "    \n",
      "\n",
      "    On iteration 34, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7377 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7377 \n",
      "    \n",
      "\n",
      "    On iteration 35, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7363 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7363 \n",
      "    \n",
      "\n",
      "    On iteration 36, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7355 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7355 \n",
      "    \n",
      "\n",
      "    On iteration 37, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7312 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7312 \n",
      "    \n",
      "\n",
      "    On iteration 38, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7369 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7369 \n",
      "    \n",
      "\n",
      "    On iteration 39, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7293 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7293 \n",
      "    \n",
      "\n",
      "    On iteration 40, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7350 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.735 \n",
      "    \n",
      "\n",
      "    On iteration 41, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7344 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7344 \n",
      "    \n",
      "\n",
      "    On iteration 42, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7388 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7388 \n",
      "    \n",
      "\n",
      "    On iteration 43, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7361 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7361 \n",
      "    \n",
      "\n",
      "    On iteration 44, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7351 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7351 \n",
      "    \n",
      "\n",
      "    On iteration 45, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7301 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7301 \n",
      "    \n",
      "\n",
      "    On iteration 46, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7364 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7364 \n",
      "    \n",
      "\n",
      "    On iteration 47, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7365 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7365 \n",
      "    \n",
      "\n",
      "    On iteration 48, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7315 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7315 \n",
      "    \n",
      "\n",
      "    On iteration 49, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7370 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.737 \n",
      "    \n",
      "\n",
      "    On iteration 50, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7384 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7384 \n",
      "    \n",
      "\n",
      "    On iteration 51, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7413 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7413 \n",
      "    \n",
      "\n",
      "    On iteration 52, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7400 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.74 \n",
      "    \n",
      "\n",
      "    On iteration 53, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7345 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7345 \n",
      "    \n",
      "\n",
      "    On iteration 54, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7424 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7424 \n",
      "    \n",
      "\n",
      "    On iteration 55, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7334 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7334 \n",
      "    \n",
      "\n",
      "    On iteration 56, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7367 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7367 \n",
      "    \n",
      "\n",
      "    On iteration 57, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7309 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7309 \n",
      "    \n",
      "\n",
      "    On iteration 58, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7338 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7338 \n",
      "    \n",
      "\n",
      "    On iteration 59, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7333 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7333 \n",
      "    \n",
      "\n",
      "    On iteration 60, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7281 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7281 \n",
      "    \n",
      "\n",
      "    On iteration 61, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7442 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7442 \n",
      "    \n",
      "\n",
      "    On iteration 62, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7348 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7348 \n",
      "    \n",
      "\n",
      "    On iteration 63, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7353 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7353 \n",
      "    \n",
      "\n",
      "    On iteration 64, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7377 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7377 \n",
      "    \n",
      "\n",
      "    On iteration 65, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7467 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7467 \n",
      "    \n",
      "\n",
      "    On iteration 66, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7415 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7415 \n",
      "    \n",
      "\n",
      "    On iteration 67, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7317 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7317 \n",
      "    \n",
      "\n",
      "    On iteration 68, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7431 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7431 \n",
      "    \n",
      "\n",
      "    On iteration 69, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7284 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7284 \n",
      "    \n",
      "\n",
      "    On iteration 70, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7330 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.733 \n",
      "    \n",
      "\n",
      "    On iteration 71, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7333 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7333 \n",
      "    \n",
      "\n",
      "    On iteration 72, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7361 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7361 \n",
      "    \n",
      "\n",
      "    On iteration 73, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7419 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7419 \n",
      "    \n",
      "\n",
      "    On iteration 74, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7391 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7391 \n",
      "    \n",
      "\n",
      "    On iteration 75, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7421 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7421 \n",
      "    \n",
      "\n",
      "    On iteration 76, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7313 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7313 \n",
      "    \n",
      "\n",
      "    On iteration 77, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7315 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7315 \n",
      "    \n",
      "\n",
      "    On iteration 78, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7310 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.731 \n",
      "    \n",
      "\n",
      "    On iteration 79, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7356 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7356 \n",
      "    \n",
      "\n",
      "    On iteration 80, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7373 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7373 \n",
      "    \n",
      "\n",
      "    On iteration 81, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7429 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7429 \n",
      "    \n",
      "\n",
      "    On iteration 82, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7394 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7394 \n",
      "    \n",
      "\n",
      "    On iteration 83, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7385 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7385 \n",
      "    \n",
      "\n",
      "    On iteration 84, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7320 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.732 \n",
      "    \n",
      "\n",
      "    On iteration 85, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7326 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7326 \n",
      "    \n",
      "\n",
      "    On iteration 86, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7317 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7317 \n",
      "    \n",
      "\n",
      "    On iteration 87, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7387 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7387 \n",
      "    \n",
      "\n",
      "    On iteration 88, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7369 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7369 \n",
      "    \n",
      "\n",
      "    On iteration 89, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7319 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7319 \n",
      "    \n",
      "\n",
      "    On iteration 90, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7376 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7376 \n",
      "    \n",
      "\n",
      "    On iteration 91, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7347 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7347 \n",
      "    \n",
      "\n",
      "    On iteration 92, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7262 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7262 \n",
      "    \n",
      "\n",
      "    On iteration 93, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7430 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.743 \n",
      "    \n",
      "\n",
      "    On iteration 94, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7317 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7317 \n",
      "    \n",
      "\n",
      "    On iteration 95, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7339 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7339 \n",
      "    \n",
      "\n",
      "    On iteration 96, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7319 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7319 \n",
      "    \n",
      "\n",
      "    On iteration 97, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7332 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7332 \n",
      "    \n",
      "\n",
      "    On iteration 98, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7359 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7359 \n",
      "    \n",
      "\n",
      "    On iteration 99, we executed 10000 times the first 100 steps of the markov chain\n",
      "    and we captured the running state in state \"A wins\" 7348 times.\n",
      "    So we estimate the Pr[X_100 = \"A wins\" | X_0 = \"A wins\"] to be 0.7348 \n",
      "    \n",
      " \n",
      "    The sample mean is 0.73550 and the sample variance is 0.00002\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import statistics as stat\n",
    "from simple_markov_chain_lib import markov_chain\n",
    "\n",
    "random.seed(2016)  # for reproducibility\n",
    "\n",
    "p = 3/5  # probability that player A wins\n",
    "q = 2/5  # probability that player B wins equals 1-p\n",
    "\n",
    "init_probs = {0: 1.0} \n",
    " \n",
    "markov_table = {\n",
    "    0: {1: p, 2: q},       # 0  -> 0-0\n",
    "    1: {3: p, 4: q},       # 1  -> 15-0\n",
    "    2: {4: p, 5: q},       # 2  -> 0-15\n",
    "    3: {6: p, 7: q},       # 3  -> 30-0\n",
    "    4: {7: p, 8: q},       # 4  -> 15-15\n",
    "    5: {8: p, 9: q},       # 5  -> 0-30\n",
    "    6: {10: q, 15: p},     # 6  -> 40-0\n",
    "    7: {10: p, 11: q},     # 7  -> 30-15\n",
    "    8: {11: p, 12: q},     # 8  -> 15-30\n",
    "    9: {12: p, 16: q},     # 9  -> 0-40\n",
    "    10: {13: q, 15: p},    # 10 -> 40-15\n",
    "    11: {13: p, 14: q},    # 11 -> 30-30   (\"Deuce\")\n",
    "    12: {14: p, 16: q},    # 12 -> 15-40\n",
    "    13: {11: q, 15: p},    # 13 -> 40-30\n",
    "    14: {11: p, 16: q},    # 14 -> 30-40\n",
    "    15: {15: 1.},          # 15 -> \"A wins\"\n",
    "    16: {16: 1.}           # 16 -> \"B wins\"\n",
    "}\n",
    " \n",
    "mc = markov_chain(markov_table, init_probs)\n",
    "\n",
    "N = 10000   # number of samples\n",
    "steps = 100   # the target time\n",
    "counter = 0  # to count the number of times the event {X_40  = 0} occurs\n",
    "M = 100     # number of iterations of initial experiment\n",
    "\n",
    "estimates=[]\n",
    "\n",
    "for k in range(M):\n",
    "    counter = 0\n",
    "    for i in range(N):\n",
    "        mc.start() \n",
    "        for j in range(steps):  mc.move()\n",
    "        if mc.running_state == 15:  counter += 1\n",
    "\n",
    "    phat = counter / N\n",
    "    \n",
    "    estimates.append(phat)\n",
    "\n",
    "    print(\"\"\"\n",
    "    On iteration {4}, we executed {0} times the first {1} steps of the markov chain\n",
    "    and we captured the running state in state \"A wins\" {2} times.\n",
    "    So we estimate the Pr[X_{1} = \"A wins\" | X_0 = \"A wins\"] to be {3} \n",
    "    \"\"\".format(N, steps, counter, phat, k))\n",
    "\n",
    "print(\n",
    "    \"\"\" \n",
    "    The sample mean is {0:.5f} and the sample variance is {1:.5f}\n",
    "    \"\"\".format(stat.mean(estimates), stat.variance(estimates))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Παρατηρήσαμε τα εξής: πειραματιστήκαμε με τις τιμές για τα Ν, Μ, steps. Τα steps έμειναν στην τιμή 100, ενώ δοκιμάσαμε και τις τιμές 10, 100, 200, χωρίς αισθητή αλλαγή. Βέβαια, μεταβάλλοντας την τιμή των steps, βλέπουμε ότι η εκτιμήτρια έχει πολύ μικρή απόκλιση. Αυτό οφείλεται στην ισχύ του Νόμου των Μεγάλων Αριθμών, καθώς έχουμε μεγάλα Ν. Εκτελέσαμε το πείραμα με M = 10, M = 100, M = 1000, και δεν παρατηρήθηκαν αξιοσημείωτες διαφορές. Το ίδιο ίσχυσε και για μεταβολές του Ν, από 100 έως 10000. Στις περιπτώσεις αυτές, παρατηρήθηκε μια μικρή μεταβολή της τάξης του $10^{-4}$. Η πειραματική μέση τιμή για το παραπάνω setting που φαίνεται στο κομμάτι κώδικα παραπάνω είναι 0.73551 και η τυπική απόκλιση 0.00023, και είναι 0.7355 ο μέσος όρος των μέσων τιμών που παρατηρήθηκαν για τις διάφορες τιμές των παραμέτρων, με πολύ μικρή τιμή για τη διασπορά. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
